space/time trade-offs in hash coding with allowable errors in this paper trade-offs among certain computational factors a given set of messages two new hash-coding methods are examined and compared with a particular conventional hash-coding method the computational factors considered are the size of the hash area space the time required to identify a message as a nonmember of the given set reject time and an allowable error frequency the new methods are intended to reduce the amount of space required to contain the hash-coded information from that associated with conventional methods the reduction in space is accomplished by exploiting the possibility that a small fraction of errors of commission may be tolerable in some applications in particular applications in which a large amount of data is involved and a core resident hash area is consequently not feasible using conventional methods in such applications it is envisaged that overall performance could be improved by using a smaller core resident hash area in conjunction with the new methods and when necessary by using some secondary and perhaps time-consuming test to catch the small fraction of errors associated with new methods an example is discussed which illustrates possible areas of application for the new methods analysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time cacm july 1970 bloom b h hash coding hash addressing scatter storage searching storage layout retrieval trade-offs retrieval efficiency storage efficiency 3.73 3.74 3.79 ca700704 jb february 13 1978 9:18 am